import { type SnippetInferenceProvider } from "@huggingface/tasks";
import type { PipelineType } from "@huggingface/tasks/src/pipelines.js";
import type { ChatCompletionInputMessage, GenerationParameters } from "@huggingface/tasks/src/tasks/index.js";
import { type InferenceSnippet, type ModelDataMinimal } from "@huggingface/tasks";
export declare const snippetBasic: (model: ModelDataMinimal, accessToken: string, provider: SnippetInferenceProvider) => InferenceSnippet[];
export declare const snippetTextGeneration: (model: ModelDataMinimal, accessToken: string, provider: SnippetInferenceProvider, providerModelId?: string, opts?: {
    streaming?: boolean;
    messages?: ChatCompletionInputMessage[];
    temperature?: GenerationParameters["temperature"];
    max_tokens?: GenerationParameters["max_tokens"];
    top_p?: GenerationParameters["top_p"];
}) => InferenceSnippet[];
export declare const snippetZeroShotClassification: (model: ModelDataMinimal, accessToken: string, provider: SnippetInferenceProvider) => InferenceSnippet[];
export declare const snippetFile: (model: ModelDataMinimal, accessToken: string, provider: SnippetInferenceProvider) => InferenceSnippet[];
export declare const curlSnippets: Partial<Record<PipelineType, (model: ModelDataMinimal, accessToken: string, provider: SnippetInferenceProvider, providerModelId?: string, opts?: Record<string, unknown>) => InferenceSnippet[]>>;
export declare function getCurlInferenceSnippet(model: ModelDataMinimal, accessToken: string, provider: SnippetInferenceProvider, providerModelId?: string, opts?: Record<string, unknown>): InferenceSnippet[];
//# sourceMappingURL=curl.d.ts.map